\documentclass{article}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{synttree}
\usepackage{graphicx}


%%%% Code from fullpage.sty to use more normal margins for printing %%%%
\topmargin 0pt
\advance \topmargin by -\headheight
\advance \topmargin by -\headsep
     
\textheight 8.9in
     
\oddsidemargin 0pt
\evensidemargin \oddsidemargin
\marginparwidth 0.5in
     
\textwidth 6.5in
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\title{Node Alignment Algorithm}
\author{AVENUE Group Rule Learner Re-Write \\
        Greg Hanneman and Jonathan Clark}


\begin{document}


\maketitle


\section{Definitions of Coverage}

We have several notions of the coverage of a node.  In the following definitions, {\it vectors} are implemented as bit sets while {\it spans} are implemented as a pair of integers.  Nodes are arranged in a source-side parse tree covering source sentece $w_1 ... w_n$ and a target-side parse tree covering target sentence $w_1' ... w_m'$.  The notation $X \leadsto y$ indicates that node $X$ dominates terminal word $y$ in a parse tree.  The source and target sentence are word aligned; an alignment between source word $w_i$ and target word $w_j'$ is shown as $w_i \leftrightarrow w_j'$.

\begin{itemize}

\item {\bf Direct coverage vector of a source node $b(S)$.}  For a node in the source-side parse tree, the contiguous range of source word indexes covered by the yield of the node.  The direct coverage vector $b(S)$ is defined as:
\begin{equation}
    b(S) = \left\{ i : S \leadsto w_i \right\}
\end{equation}

\item {\bf Direct coverage vector of a target node $b(T)$.}  Similar to the above, but for target-side nodes and target word indexes.
\begin{equation}
    b(T) = \left\{ j : T \leadsto w'_j \right\}
\end{equation}

\item {\bf Projected coverage vector of a source node $\beta(S)$.}  For a node in the source-side parse tree, the exact target word indexes covered by the node via projection through the word alignments.  For a source terminal node, the projected coverage vector comes directly from the word alignments; for a non-terminal node, it is the union of the projected coverage vectors of its children.
\begin{equation} \label{Eqn-ProjCovVector}
    \beta(S) =
    \begin{cases}
        \left\{ j : S \leadsto w_i, w_i \leftrightarrow w'_j \right\}
        & \text{if $S$ terminal} \\
        \bigcup_{k \in {\rm children}(S)} \beta(k) & {\rm otherwise} \\
    \end{cases}
\end{equation}

\item {\bf Projected coverage span of a source node $\beta_{min}(S)$, $\beta_{max}(S)$.}  Similar to the above, but only the overall minimum and maximum of the target word indexes are kept.
\begin{equation}
    \beta_{min}(S) = \min \left\{ j : j \in \beta(S) \right\}
\end{equation}
\begin{equation}
    \beta_{max}(S) = \max \left\{ j : j \in \beta(S) \right\}
\end{equation}

\item {\bf Projected complement vector of a source node $\bar{\beta}(S)$.}  For a node in the source-side parse tree, the exact target word indexes {\it not} covered by the node and its descendants.  For the source root node, the projected complement vector is a vector of all 0s in the length of the target sentences.  For other source nodes $S$, the projected complement vector $\bar{\beta}(S)$ is defined as:
\begin{equation} \label{Eqn-ProjCompVector}
    \bar{\beta}(S) = \bar{\beta}\left( {\rm parent}(S) \right) \cup \bigcup_{k \in {\rm siblings}(S)} \beta(k)
\end{equation}

\end{itemize}

The notation is apt to get quite dense, but here is its motivation: $b$ denotes the coverage bit set of a node, while the equivalent Greek letter $\beta$ denotes a projection of that bit set.  Complement bit sets are denoted with a bar: $\bar{b}$ or $\bar{\beta}$.  It is important to remember, however, that the bar syntax does not indicate a logical {\tt NOT} operation: $\beta$ and $\bar{\beta}$ are not simply bitwise negations of each other.


\section{T2T Alignment}

\subsection{Procedure}

\begin{enumerate}

\item Read in the source tree, target tree, and Viterbi alignments between them.  When the source tree is read in, compute the direct coverage vector of each source node.  When the target tree is read in, compute the direct coverage vector of each target node.

\item In a bottom-up procedure, compute the projected coverage vector and projected coverage span of each source and target node.  For a terminal node, the projected coverage vector is the set of target word indexes the source terminal is aligned to.  For a non-terminal node, the projected coverage vector is the union of projected coverage vectors of the node's children.  (See Equation \ref{Eqn-ProjCovVector}.)  For any node, the projected coverage span is the minimum and maximum indexes of bits set in the projected coverage vector.

\item In a top-down procedure, compute the projected complement vector of each source node.  For the root node, the projected complement vector is initialized to all 0s.  For other nodes, the projected complement vector is computed as defined in Equation \ref{Eqn-ProjCompVector}.

\item Discover aligned nodes:

    \begin{enumerate}

    \item For a node $s$, if the intersection of its projected coverage span and its projected complement vector is 0, then a node alignment can be made in T2S mode.  In T2S alignment, the string-side span $s$ is aligned to is $[\beta_{min}(s), \beta_{max}(s)]$.
    \begin{equation}
        \beta(s) \cap \bar{\beta}(s) = {\bf 0} \Longrightarrow s {\rm \ consistent}
    \end{equation}

    \item To find out what the exact node alignment is for T2T mode, find an exact match between $s$'s projected coverage vector and a target node $t$'s direct coverage vector.  This check must be made in both directions to avoid unaligned boundary words.  Because projected coverage vectors do not include internal unaligned words, also construct vectors $u$ and $u'$ of unaligned source and target words and use them to fill in the gaps within projected coverage vectors.  The notation $v[a, b]$ means the subsequence of vector $v$ from position $a$ to position $b$ (inclusive).
    \begin{equation}
        \left. \begin{array}{ll}
            \beta(s) \cup u'[\beta_{min}(s), \beta_{max}(s)]= b(t) \\
            \beta(t) \cup u[\beta_{min}(t), \beta_{max}(t)]= b(s)
        \end{array} \right\} \Longrightarrow s {\rm \ aligned\ to\ } t
    \end{equation}

    \item To find ``grown'' node alignments for $s$ in T2T mode, find target nodes $t$ where the union of $s$'s projected coverage vector and a vector $u'$ of all target-side unaligned words exactly equals the union of $t$'s direct coverage vector and a vector of all target-side unaligned words.
    \begin{equation}
        \beta(s) \cup u' = b(t) \cup u' \Longrightarrow s {\rm \ aligned\ to\ } t
    \end{equation}

    \item To find grown string alignments for $s$ in T2S mode,

    \end{enumerate}

\end{enumerate}


\subsection{Example}

We word through the following example, where the tree headed at $A$ is the source and the tree headed at $Z$ is the target.  Black squares indicate word alignments links between terminal nodes.

\branchheight{0.4in}
\childattachsep{0.3in}
\childsidesep{0.3in}
\medskip
\begin{tabular}{ll}
& \synttree[Z [Y [X] [W] [V [U] [T]]] [S [R [Q] [P]] [O]]] \\
\begin{minipage}{1.4in}\rotatebox{90}{\synttree[A [B [C] [D]] [E [F [G] [H]] [I [J] [K]]]]}\end{minipage} &
\begin{minipage}{2.7in}
    \vspace{0.15in}
    \begin{tabular}{@{\extracolsep{0.16in}}ccccccc@{\vspace{0.24in}}}
    . & . & $\blacksquare$ & $\blacksquare$ & . & . & . \\
    . & . & . & . & . & . & . \\
    $\blacksquare$ & . & . & . & . & . & . \\
    . & . & . & . & . & . & $\blacksquare$ \\
    . & . & . & . & $\blacksquare$ & . & . \\
    . & . & . & . & $\blacksquare$ & . & . \\
    \end{tabular}
\end{minipage} \\
\end{tabular}

\begin{enumerate}

\item The trees are read in and the direct coverage vectors are computed.  For example, node $E$ spans words 3 through 6 in the source tree, so its direct coverage vector is $b(E) = $ {\tt <001111>}.

\begin{tabular}{ll@{\hspace{1.0in}}ll}
    {\bf Node} & {\bf $b(s)$} & {\bf Node} & {\bf $b(t)$} \\
    A & {\tt <111111>}      & Z & {\tt <1111111>} \\
    B & {\tt <110000>}      & Y & {\tt <1111000>} \\
    C & {\tt <100000>}      & X & {\tt <1000000>} \\
    D & {\tt <010000>}      & W & {\tt <0100000>} \\
    E & {\tt <001111>}      & V & {\tt <0011000>} \\
    F & {\tt <001100>}      & U & {\tt <0010000>} \\
    G & {\tt <001000>}      & T & {\tt <0001000>} \\
    H & {\tt <000100>}      & S & {\tt <0000111>} \\
    I & {\tt <000011>}      & R & {\tt <0000110>} \\
    J & {\tt <000010>}      & Q & {\tt <0000100>} \\
    K & {\tt <000001>}      & P & {\tt <0000010>} \\
      &                     & O & {\tt <0000001>} \\
\end{tabular}

\item Projected coverage vectors and spans are computed bottom-up for the source tree.  For example, source terminal node $G$ is aligned to the word 7 in the target sentence, so its projected coverage vector is $\beta(G) = $ {\tt <0000001>} and its projected coverage span is $\left( \beta_{min}(G), \beta_{max}(G) \right) = (7, 7)$.  Likewise, source terminal node $H$ is aligned to word 1 in the target tree, so $\beta(H) = $ {\tt <1000000>} and $\left( \beta_{min}(H), \beta_{max}(H) \right) = (1, 1)$.  At the non-terminal node $F$, the projected coverage vector is the union of its children's vectors, $\beta(F) = $ {\tt <1000001>}.  Thus, the projected coverage span for $F$ is $\left( \beta_{min}(F), \beta_{max}(F) \right) = (1, 7)$.

\begin{tabular}{lll}
    {\bf Node} & {\bf $\beta(s)$} & {\bf $\beta_{min}, \beta_{max}$} \\
    A & {\tt <1011101>} & 1, 7 \\
    B & {\tt <0000100>} & 5, 5 \\
    C & {\tt <0000100>} & 5, 5 \\
    D & {\tt <0000100>} & 5, 5 \\
    E & {\tt <1011001>} & 1, 7 \\
    F & {\tt <1000001>} & 1, 7 \\
    G & {\tt <0000001>} & 7, 7 \\
    H & {\tt <1000000>} & 1, 1 \\
    I & {\tt <0011000>} & 3, 4 \\
    J & {\tt <0000000>} & $\emptyset$, $\emptyset$ \\
    K & {\tt <0011000>} & 3, 4 \\
\end{tabular}

\item Projected complement vectors are computed top-down for the source tree.  For example, source node $F$ has parent $E$ and sibling $I$, so the projected complement vector at $F$ is $\bar{\beta}(F) = \bar{\beta}(E) \cup \beta(I)$.  At this point in the computation $\bar{\beta}(E)$ has already been set to {\tt <0000100>}, and $\beta(I)$ in the previous step was found to be {\tt <0011000>}.  Therefore, $\bar{\beta}(F) = $ {\tt <0000100>} $\cup$ {\tt <0011000>}, or {\tt <0011100>}.

\begin{tabular}{lll}
    {\bf Node} & {\bf $\bar{\beta}(s)$} \\
    A & {\tt <0000000>} \\
    B & {\tt <1011001>} \\
    C & {\tt <1011101>} \\
    D & {\tt <1011101>} \\
    E & {\tt <0000100>} \\
    F & {\tt <0011100>} \\
    G & {\tt <1011100>} \\
    H & {\tt <0011101>} \\
    I & {\tt <1000101>} \\
    J & {\tt <1011101>} \\
    K & {\tt <1000101>} \\
\end{tabular}

\item Node alignments are discovered in three stages:

    \begin{enumerate}

    \item Nodes are checked for consistency by comparing their projected coverage spans and projected complement vectors.  For example, source node $F$ has projected coverage span $\left( \beta_{min}(F), \beta_{max}(F) \right) = (1, 7)$, which is cast to a vector $\beta_{min...max}(F) = $ {\tt <1111111>}.  $F$ also has projected complement vector $\bar{\beta}(F) = $ {\tt <0011100>}.  The intersection of these two vectors is {\tt <0011100>}, which is non-zero, so $F$ is not consistently aligned.

    \begin{tabular}{lll}
        {\bf Node} & {\bf $\beta_{min..max}(s) \cap \bar{\beta}(s)$} & {\bf Consistent?} \\
        A & {\tt <0000000>} & Yes \\
        B & {\tt <0000000>} & Yes \\
        C & {\tt <0000100>} & No \\
        D & {\tt <0000100>} & No \\
        E & {\tt <0000100>} & No \\
        F & {\tt <0011100>} & No \\
        G & {\tt <0000000>} & Yes \\
        H & {\tt <0000000>} & Yes \\
        I & {\tt <0000000>} & Yes \\
        J & {\tt < $\emptyset$ >} & No \\
        K & {\tt <0000000>} & Yes \\
    \end{tabular}

    \item The consistent source nodes are aligned to target nodes by exact match of (1) a source node's projected coverage vector union all target-side unaligned words within that span with a target node's direct coverage vector, and (2) the target node's projected coverage vector union all source-side unaligned words within that span with the source node's direct coverage vector.  
For example, source node $A$ has projected coverage vector $\beta(A) = $ {\tt <1011101>}.  The unaligned target words vector between positions 1 and 7 is $u'[1,7] = $ {\tt <0100010>}.  On the target side, node $Z$ has direct coverage vector $b(Z) = $ {\tt <1111111>}.  Thus, $\beta(A) \cup u'[1,7] = $ {\tt <1111111>} $ = b(Z)$.  In the reverse direction, target node $Z$ has projected coverage vector $\beta(Z) = $ {\tt <111101>}, and the unaligned source words vector between 1 and 6 is $u[1, 6] = $ {\tt <000010>}.  The union of these two vectors exactly equals the direct coverage vector of $b(A)$, or {\tt <111111>}.  Therefore, nodes $A$ and $Z$ are aligned.

    \begin{tabular}{ll}
        {\bf Node} & {\bf Alignments} \\
        A & Z \\
        B & Q \\
        G & O \\
        H & X \\
        K & V \\
    \end{tabular}

    \item ``Grown'' alignments for consistent nodes are calculated.  A vector $u'$ of all unaligned words in the target tree is calculated and included via union on both sides of the exact match test between a projected coverage vector and a direct coverage vector.  For example, $u' = $ {\tt <0100010>}.  Now, at source node $B$, $\beta(B) \cup u' = $ {\tt <0100110>}.  On the target side there are two matches: $b(R) \cup u' = $ {\tt <0100110>} and $b(Q) \cup u' = $ {\tt <0100110>}.  Thus, node $B$ now aligns to both node $Q$ and node $R$.

    \begin{tabular}{ll}
        {\bf Node} & {\bf Alignments} \\
        A & Z \\
        B & Q, R \\
        G & O \\
        H & X \\
        I & V \\
        K & V \\
    \end{tabular}

    \end{enumerate}

\end{enumerate}



%\bibliographystyle{fullname}
%\bibliography{rough2}


\end{document}

